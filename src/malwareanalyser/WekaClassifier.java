/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package malwareanalyser;

import java.io.File;
import java.io.IOException;
import java.sql.Timestamp;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import weka.core.Instances;
import weka.core.converters.CSVSaver;
import weka.core.converters.ConverterUtils.DataSource;
import weka.classifiers.Evaluation;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.trees.J48;
import weka.classifiers.trees.RandomForest;
import weka.classifiers.bayes.NaiveBayes;
import weka.classifiers.bayes.NaiveBayesMultinomial;
import weka.classifiers.lazy.IBk;
import weka.classifiers.evaluation.ThresholdCurve;
import weka.classifiers.functions.SMO;
import weka.filters.unsupervised.attribute.Remove;

import org.apache.commons.io.FileUtils;

/**
 *
 * @author msgeden
 */
public class WekaClassifier {

	public static void main(String[] args) throws IOException {
		String filePath1 = "/Users/msgeden/Desktop/Combination/train_dex_4-grams_8000_1.arff";
		String filePath2 = "/Users/msgeden/Desktop/Combination/train_perm_5-grams_8000_3.arff";
		getCombinedResults(filePath1, filePath2);
		String filePath3 = "/Users/msgeden/Desktop/Combination/test_dex_4-grams_8000_1.arff";
		String filePath4 = "/Users/msgeden/Desktop/Combination/test_perm_5-grams_8000_3.arff";
		getCombinedResults(filePath3, filePath4);

	}

	public static void getCombinedResults(String filePath1, String filePath2) throws IOException {

		File file1 = new File(filePath1);
		ArrayList<String> attributes1 = new ArrayList<String>();
		HashMap<String, String> vectors1 = new HashMap<String, String>();
		List<String> lines1 = FileUtils.readLines(file1);
		boolean data1 = false;
		for (int i = 0; i < lines1.size(); i++) {
			if (!data1) {
				if (lines1.get(i).startsWith("@attribute") && !lines1.get(i).contains(" class ")) {
					attributes1.add(lines1.get(i));
				}
			} else {
				String[] features = lines1.get(i).split(",");
				StringBuilder sb = new StringBuilder();
				for (int j = 1; j < features.length - 1; j++)
					sb.append(features[j] + ",");
				vectors1.put(features[0], sb.toString());
			}
			if (lines1.get(i).startsWith("@data"))
				data1 = true;
		}
		File file2 = new File(filePath2);
		ArrayList<String> attributes2 = new ArrayList<String>();
		HashMap<String, String> vectors2 = new HashMap<String, String>();
		List<String> lines2 = FileUtils.readLines(file2);
		boolean data2 = false;
		for (int i = 0; i < lines2.size(); i++) {
			if (!data2) {
				if (lines2.get(i).startsWith("@attribute") && !lines2.get(i).contains(" appname ")) {
					attributes2.add(lines2.get(i));
				}
			} else {
				String[] features = lines2.get(i).split(",");
				StringBuilder sb = new StringBuilder();
				for (int j = 1; j < features.length; j++)
					if (j!=features.length-1)
						sb.append(features[j] + ",");
					else
						sb.append(features[j]);
				vectors2.put(features[0], sb.toString());
			}
			if (lines2.get(i).startsWith("@data"))
				data2 = true;
		}
		HashMap<String, String> mergedVectors = new HashMap<String, String>();
		
		for (Map.Entry<String, String> entry : vectors1.entrySet()) {
			if (vectors2.containsKey(entry.getKey()))
			{
				String secondPart = vectors2.get(entry.getKey());
				mergedVectors.put(entry.getKey(), entry.getValue()+secondPart);
			}
		}
		for (String attribute:attributes2)
			attributes1.add(attribute);
		
		String filePath = file1.getAbsolutePath();
		File newArffFile = new File(file1.getAbsolutePath().substring(0,filePath.length()-5)+"_merged.arff");
		FileUtils.deleteQuietly(newArffFile);
		FileUtils.write(newArffFile, "@relation 'ngram'\n", true);
		for (String attribute:attributes1)
		{
			FileUtils.write(newArffFile, attribute+"\n", true);
		}
		FileUtils.write(newArffFile, "@data\n", true);
		for (Map.Entry<String, String> entry : mergedVectors.entrySet()) {
			FileUtils.write(newArffFile, entry.getKey()+","+entry.getValue()+"\n", true);
		}

	}

	public static void getClassifierResultsForAllNgrams(String featureType) {
		try {
			String extension = FileHandler
					.readConfigValue(Constants.FILE_EXTENSION_CONFIG);
			Date date = new Date();
			String modifiedDate = new SimpleDateFormat("dd-MM-yyyy")
					.format(date);
			String resultTablePath = FileHandler
					.readConfigValue(Constants.REPORTS_PATH_CONFIG)
					+ extension
					+ Constants.UNDERSCORE
					+ featureType
					+ Constants.UNDERSCORE
					+ "weka_total_" + modifiedDate + ".tsv";
			File results = new File(resultTablePath);

			String[] inputSizes = FileHandler.readConfigValue(
					Constants.NUMBER_OF_DATA_INPUT_CONFIG).split(",");

			for (int i = 0; i < Constants.EXTRACTION_LABELS.length; i++) {
				FileUtils.write(results,
						"\nExtension\tExtraction\tFeature\tTimestamp", true);
				FileUtils.write(results, "\n" + extension + "\t"
						+ Constants.EXTRACTION_LABELS[i] + "\t" + featureType
						+ "\t" + new Timestamp(new Date().getTime()), true);
				FileUtils
						.write(results,
								"\nInput Size\tMNB\tROC(M)\tTPR(M)\tFPR(M)\tNB\tROC(M)\tTPR(M)\tFPR(M)\tKNN("
										+ FileHandler
												.readConfigValue(Constants.KNN_KVALUE_CONFIG)
										+ ")\tROC(M)\tTPR(M)\tFPR(M)\tJ48\tROC(M)\tTPR(M)\tFPR(M)\tRF\tROC(M)\tTPR(M)\tFPR(M)\tSVM",
								true);
				for (String inputSize : inputSizes) {
					FileUtils.write(results, "\n" + inputSize, true);
					String trainingDataPath = FileHandler
							.readConfigValue(Constants.REPORTS_PATH_CONFIG)
							+ Constants.TRAIN_LABEL
							+ File.separator
							+ "train"
							+ Constants.UNDERSCORE
							+ extension
							+ Constants.UNDERSCORE
							+ featureType
							+ Constants.UNDERSCORE
							+ inputSize
							+ Constants.UNDERSCORE + i + ".arff";

					String testDataPath = FileHandler
							.readConfigValue(Constants.REPORTS_PATH_CONFIG)
							+ Constants.TEST_LABEL
							+ File.separator
							+ "test"
							+ Constants.UNDERSCORE
							+ extension
							+ Constants.UNDERSCORE
							+ featureType
							+ Constants.UNDERSCORE
							+ inputSize
							+ Constants.UNDERSCORE + i + ".arff";

					String[] mnb = getClassifierResults(trainingDataPath,
							testDataPath, extension, "mnb", featureType);
					FileUtils.write(results, "\t" + mnb[0] + "%\t" + mnb[1]
							+ "\t" + mnb[2] + "\t" + mnb[3], true);

					String[] nb = getClassifierResults(trainingDataPath,
							testDataPath, extension, "nb", featureType);
					FileUtils.write(results, "\t" + nb[0] + "%\t" + nb[1]
							+ "\t" + nb[2] + "\t" + nb[3], true);

					String[] knn = getClassifierResults(trainingDataPath,
							testDataPath, extension, "knn", featureType);
					FileUtils.write(results, "\t" + knn[0] + "%\t" + knn[1]
							+ "\t" + knn[2] + "\t" + knn[3], true);

					String[] j48 = getClassifierResults(trainingDataPath,
							testDataPath, extension, "j48", featureType);
					FileUtils.write(results, "\t" + j48[0] + "%\t" + j48[1]
							+ "\t" + j48[2] + "\t" + j48[3], true);

					String[] rf = getClassifierResults(trainingDataPath,
							testDataPath, extension, "rf", featureType);
					FileUtils.write(results, "\t" + rf[0] + "%\t" + rf[1]
							+ "\t" + rf[2] + "\t" + rf[3], true);

					String[] svm = getClassifierResults(trainingDataPath,
							testDataPath, extension, "svm", featureType);
					FileUtils.write(results, "\t" + svm[0] + "%\t" + svm[1]
							+ "\t" + svm[2] + "\t" + svm[3], true);
				}
			}

		} catch (Exception e) {
			e.printStackTrace();
		}
	}

	public static String[] getClassifierResults(String trainingDataPath,
			String testDataPath, String extension, String algorithm,
			String featureType) {
		String[] response = new String[] { "", "", "", "" };

		try {
			if (algorithm.equals("all")) {
				getClassifierResults(trainingDataPath, testDataPath, extension,
						"mnb", featureType);
				getClassifierResults(trainingDataPath, testDataPath, extension,
						"nb", featureType);
				getClassifierResults(trainingDataPath, testDataPath, extension,
						"knn", featureType);
				getClassifierResults(trainingDataPath, testDataPath, extension,
						"j48", featureType);
				getClassifierResults(trainingDataPath, testDataPath, extension,
						"rf", featureType);
				getClassifierResults(trainingDataPath, testDataPath, extension,
						"svm", featureType);

			} else {

				String resultsPath = FileHandler
						.readConfigValue(Constants.REPORTS_PATH_CONFIG)
						+ ("weka" + Constants.UNDERSCORE + algorithm
								+ Constants.UNDERSCORE + extension
								+ Constants.UNDERSCORE + featureType + ".log")
								.toLowerCase();

				File resultsFile = new File(resultsPath);
				// FileUtils.deleteQuietly(resultsFile);

				// Training Instances
				DataSource trainingSource = new DataSource(trainingDataPath);
				Instances trainingData = trainingSource.getDataSet();
				if (trainingData.classIndex() == -1) {
					trainingData
							.setClassIndex(trainingData.numAttributes() - 1);
				}

				// Test Instances
				DataSource testSource = new DataSource(testDataPath);
				Instances testData = testSource.getDataSet();
				if (testData.classIndex() == -1) {
					testData.setClassIndex(testData.numAttributes() - 1);
				}
				int numberOfFeatures = trainingData.numAttributes();
				Remove rm = new Remove();
				if (trainingData.attribute(0).name().equals("appname")) {
					numberOfFeatures -= 1;
					rm.setAttributeIndices("1"); // remove 1st attribute since
													// it is
				}
				// id
				FilteredClassifier fc = new FilteredClassifier();
				fc.setFilter(rm);
				if (algorithm.equals("j48")) {
					J48 j48 = new J48();
					j48.setUnpruned(true);
					fc.setClassifier(j48);
				} else if (algorithm.equals("nb")) {
					NaiveBayes nb = new NaiveBayes();
					fc.setClassifier(nb);
				} else if (algorithm.equals("mnb")) {
					NaiveBayesMultinomial nb = new NaiveBayesMultinomial();
					fc.setClassifier(nb);
				} else if (algorithm.equals("knn")) {
					IBk ibk = new IBk();
					ibk.setKNN(Integer.parseInt(FileHandler
							.readConfigValue((Constants.KNN_KVALUE_CONFIG))));
					fc.setClassifier(ibk);
				} else if (algorithm.equals("rf")) {
					RandomForest rf = new RandomForest();
					fc.setClassifier(rf);
				} else if (algorithm.equals("svm")) {
					SMO svm = new SMO();
					svm.setBuildLogisticModels(true);
					fc.setClassifier(svm);
				}
				// train and make predictions
				fc.buildClassifier(trainingData);

				// evaluate classifier and print some statistics
				// String[] evalOptions = new String[2];
				// evalOptions[0] = "-t";
				// evalOptions[1] = "/some/where/somefile.arff";

				Evaluation eval = new Evaluation(trainingData);
				eval.evaluateModel(fc, testData);
				
				ThresholdCurve tc = new ThresholdCurve();
				int classIndex = 1;
				Instances result = tc.getCurve(eval.predictions(), classIndex);
					
				CSVSaver csvSaver = new CSVSaver();
				csvSaver.setInstances(result);
				String fileName = new File(trainingDataPath).getName();
				fileName = fileName.substring(fileName.indexOf(Constants.UNDERSCORE)+1, fileName.lastIndexOf("."));
				String rocData = 
						FileHandler
						.readConfigValue(Constants.REPORTS_PATH_CONFIG)
						+ (fileName + Constants.UNDERSCORE + algorithm + ".csv")
								.toLowerCase();

				csvSaver.setFile(new File(rocData));
				csvSaver.writeBatch();
				
				response[0] = String.format("%.2f", eval.pctCorrect());
				response[1] = String.format("%.4f", eval.areaUnderROC(1));
				response[2] = String.format("%.4f", eval.truePositiveRate(1));
				response[3] = String.format("%.4f", eval.falsePositiveRate(1));
				System.out.println(eval.toSummaryString("\nSummary Results: "
						+ algorithm.toUpperCase() + ","
						+ (numberOfFeatures - 1) + "\n============\n", false));
				System.out
						.println(eval
								.toClassDetailsString("\nClass Details\n============\n"));
				System.out.println(eval
						.toMatrixString("\nMatrix Results\n============\n"));
				System.out.println("\nApps\n======\n");

				FileUtils.write(
						resultsFile,
						eval.toSummaryString(
								"\nSummary Results: " + algorithm.toUpperCase()
										+ "," + (numberOfFeatures - 1)
										+ "\n============\n", false), true);
				FileUtils
						.write(resultsFile,
								eval.toClassDetailsString("\nClass Details\n============\n"),
								true);
				FileUtils
						.write(resultsFile,
								eval.toMatrixString("\nMatrix Results\n============\n"),
								true);
				// FileUtils.write(resultsFile, "\nApps\n======\n", true);
				//
				// for (int i = 0; i < testData.numInstances(); i++) {
				// double pred = fc.classifyInstance(testData.instance(i));
				// System.out.print("Name: "
				// + testData.instance(i).stringValue(0));
				// FileUtils.write(resultsFile, "Name: "
				// + testData.instance(i).stringValue(0), true);
				// System.out.print(", Actual: "
				// + testData.classAttribute().value(
				// (int) testData.instance(i).classValue()));
				// FileUtils.write(
				// resultsFile,
				// ", Actual: "
				// + testData.classAttribute().value(
				// (int) testData.instance(i)
				// .classValue()), true);
				// System.out.println(", Predicted: "
				// + testData.classAttribute().value((int) pred));
				// FileUtils.write(resultsFile, ", Predicted: "
				// + testData.classAttribute().value((int) pred)
				// + "\n", true);
				// }
			}

		} catch (Exception e) {
			e.printStackTrace();
		}
		return response;
	}
}
