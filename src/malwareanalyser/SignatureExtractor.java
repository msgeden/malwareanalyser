/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package malwareanalyser;

import java.util.*;
import java.io.File;
import java.io.FilenameFilter;
import java.io.IOException;

import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;

import org.apache.commons.codec.digest.DigestUtils;
import org.apache.commons.io.FileUtils;
import org.apache.commons.lang3.ArrayUtils;
import org.apache.commons.lang3.time.StopWatch;
import org.w3c.dom.Document;
import org.w3c.dom.NodeList;
import org.w3c.dom.Node;
import org.w3c.dom.Element;

/**
 *
 * @author msgeden
 */
public class SignatureExtractor {

//	public static void main(String[] args) throws IOException {
//		File file = new File(
//				"/Users/msgeden/Desktop/MalwareAnalyser/bin/apkdownloader/Factorial.class");
//		StringBuilder cpSb = new StringBuilder();
//		ClassParser parser;
//		parser = new ClassParser(file.getAbsolutePath());
//		JavaClass clazz = parser.parse();
//		ClassGen cg = new ClassGen(clazz);
//		ConstantPool cp = clazz.getConstantPool();
//		org.apache.bcel.classfile.Method[] methods = clazz.getMethods();
//		ConstantPoolGen cpg = new ConstantPoolGen(cp);
//		MethodGen mg = new MethodGen(methods[2], clazz.getClassName(), cpg);
//		ControlFlowGraph cfg = new ControlFlowGraph(mg);
//
//		InstructionFactory f = new InstructionFactory(cg);
//		InstructionList il = new InstructionList();
//		System.out.println("test:" + cfg.toString());
//	}

	public static HashMap<String, Short[]> constructHashesPerApp(
			HashMap<String, Short[]> cumulativeHashes, String appPath,
			String extension, boolean isTestData, File reportFile,
			String signatureType) {

		try {
			// Collect all files under the path of given app
			Collection<File> files = FileHandler.findFiles(appPath,
					new String[] { extension });

			// This will keep the information whether given app owns hashes
			HashSet<String> hashes = new HashSet<String>();

			// Retrieve class type, its name and its integer array index from
			// file path
			boolean taxon = appPath.contains(File.separator
					+ Constants.CLASS_A_NAME + File.separator);
			String className = taxon ? Constants.CLASS_A_NAME
					: Constants.CLASS_B_NAME;
			int classFrequencyIndex = taxon ? 0 : 1;

			// Retrieve app name from file path
			String[] folders = appPath.split(File.separator);
			String appName = folders[folders.length - 1];
			// Number of files traversed
			int fileIterator = -1;

			// Performance monitor watch
			StopWatch watch = new StopWatch();
			watch.reset();
			watch.start();

			// Traverse app files to be analyzed
			for (File file : files) {
				fileIterator++;
				String[] fileContent = FileHandler.readFileToString(
						file.getAbsolutePath()).split("\n");
				String patternString = "";
				if (extension.equals(Constants.BERTILLONAGE_CLASS_EXTENSION)
						|| extension
								.equals(Constants.BERTILLONAGE_DEX_EXTENSION)) {
					if (signatureType.equals(Constants.CLASS_UNIT))
						patternString = "C:    ";
					else if (signatureType.equals(Constants.FIELD_UNIT))
						patternString = "\tF:    ";
					else if (signatureType.equals(Constants.METHOD_UNIT))
						patternString = "\tM:    ";
					else if (signatureType.equals(Constants.HASH_UNIT))
						patternString = "H:    ";
					else
						patternString = "H:    ";

					for (String s : fileContent) {
						if (s.startsWith(patternString)) {
							hashes.add(s.substring(s.indexOf(patternString)
									+ patternString.length()));
						}
					}
				} else if (extension.equals(Constants.PERM_EXTENSION)) {
					DocumentBuilderFactory dbFactory = DocumentBuilderFactory
							.newInstance();
					DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();
					Document doc = dBuilder.parse(file);
					doc.getDocumentElement().normalize();
					NodeList nList = doc
							.getElementsByTagName("uses-permission");
					for (int temp = 0; temp < nList.getLength(); temp++) {
						Node nNode = nList.item(temp);
						if (nNode.getNodeType() == Node.ELEMENT_NODE) {
							Element eElement = (Element) nNode;
							hashes.add(eElement.getAttribute("android:name"));
						}
					}
				} else if (extension.equals(Constants.MANF_EXTENSION)) {
					patternString = "SHA1-Digest: ";
					for (String s : fileContent) {
						if (s.startsWith(patternString)) {
							hashes.add(s.substring(s.indexOf(patternString)
									+ patternString.length()).replace("\n", "").replace("\r",""));
						}
					}
				}
			}
			// Merge app hash set with cumulative hash hashmap
			for (String hash : hashes) {
				if (cumulativeHashes.containsKey(hash)) {
					Short[] classFrequencies = cumulativeHashes.get(hash);
					classFrequencies[classFrequencyIndex] = (short) (classFrequencies[classFrequencyIndex] + 1);
					cumulativeHashes.put(hash, classFrequencies);
				} else {
					Short[] classFrequencies = new Short[] { 0, 0 };
					classFrequencies[classFrequencyIndex] = 1;
					cumulativeHashes.put(hash, classFrequencies);
				}
			}

			// These values are stored in hashes hashmap not to iterate once
			// more during the information gain calculation
			if (cumulativeHashes.containsKey(Constants.COUNT_OF_APPS_PER_CLASS)) {
				Short[] appCountsForClasses = cumulativeHashes
						.get(Constants.COUNT_OF_APPS_PER_CLASS);
				appCountsForClasses[classFrequencyIndex] = (short) (appCountsForClasses[classFrequencyIndex] + 1);
				cumulativeHashes.put(Constants.COUNT_OF_APPS_PER_CLASS,
						appCountsForClasses);
			} else {
				Short[] appCountsForClasses = new Short[] { 0, 0 };
				appCountsForClasses[classFrequencyIndex] = 1;
				cumulativeHashes.put(Constants.COUNT_OF_APPS_PER_CLASS,
						appCountsForClasses);
			}

			// Print the number of unique hashes, files are processed.
			// Print the number of unique hashes, files are processed.
			FileUtils.write(reportFile, className + Constants.TAB_CHAR
					+ extension + Constants.TAB_CHAR + hashes.size()
					+ Constants.TAB_CHAR + cumulativeHashes.size()
					+ Constants.TAB_CHAR + (fileIterator + 1)
					+ Constants.TAB_CHAR + (double) watch.getTime() / 1000.0
					+ Constants.TAB_CHAR + appName + "\n", true);
			System.out.print(className + Constants.TAB_CHAR + extension
					+ Constants.TAB_CHAR + hashes.size() + Constants.TAB_CHAR
					+ cumulativeHashes.size() + Constants.TAB_CHAR
					+ (fileIterator + 1) + Constants.TAB_CHAR
					+ (double) watch.getTime() / 1000.0 + Constants.TAB_CHAR
					+ appName + "\n");

		} catch (Exception e) {
			e.printStackTrace();
		}
		return cumulativeHashes;
	}

	public static HashMap<String, Short[]> constructHashes(String dataPath,
			String extension, boolean isTestData, String signatureType) {

		HashMap<String, Short[]> hashes = new HashMap<String, Short[]>();
		try {
			String[] appPaths = appPathsOfGivenClass(dataPath, extension,
					isTestData);

			// Data class label for reports and input files
			String trainOrTestLabel = isTestData ? Constants.TEST_LABEL
					: Constants.TRAIN_LABEL;

			// Generate report file name
			String reportFilePath = FileHandler
					.readConfigValue(Constants.REPORTS_PATH_CONFIG)
					+ (trainOrTestLabel + Constants.UNDERSCORE + extension
							+ Constants.UNDERSCORE + signatureType
							+ Constants.UNDERSCORE + "report.tsv")
							.toLowerCase();

			File reportFile = new File(reportFilePath);
			FileUtils.deleteQuietly(reportFile);

			FileUtils.write(reportFile, "Class" + Constants.TAB_CHAR
					+ "Extension" + Constants.TAB_CHAR + "# of Hashes"
					+ Constants.TAB_CHAR + "# of Total Hashes"
					+ Constants.TAB_CHAR + "Number of Files"
					+ Constants.TAB_CHAR + "Time Elapsed" + Constants.TAB_CHAR
					+ "App Name" + Constants.TAB_CHAR + "\n", true);
			System.out.print("Number" + Constants.TAB_CHAR + "Class"
					+ Constants.TAB_CHAR + "Extension" + Constants.TAB_CHAR
					+ "# of Hashes" + Constants.TAB_CHAR + "# of Total Hashes"
					+ Constants.TAB_CHAR + "Number of Files"
					+ Constants.TAB_CHAR + "Time Elapsed" + Constants.TAB_CHAR
					+ "App Name" + Constants.TAB_CHAR + "\n");
			int count = 0;
			for (String appPath : appPaths) {
				System.out.print((++count) + Constants.TAB_CHAR);
				hashes = constructHashesPerApp(hashes, appPath, extension,
						isTestData, reportFile, signatureType);
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
		return hashes;
	}

	public static String extractDistinctiveHashesByNormalizedDifference(
			HashMap<String, Short[]> hashes, String extension) {
		// Top-ranked hash features file name generation
		String signatureType = FileHandler
				.readConfigValue(Constants.SIGNATURE_ENTITY_TYPE);

		String rankedHashesPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ (extension + Constants.UNDERSCORE + "distinctive"
						+ Constants.UNDERSCORE + signatureType
						+ Constants.UNDERSCORE + "by_difference.tsv")
						.toLowerCase();
		File rankedHashesFile = new File(rankedHashesPath);
		StopWatch watch = new StopWatch();
		watch.reset();
		watch.start();

		// Try to delete if it exists without exception
		FileUtils.deleteQuietly(rankedHashesFile);
		System.out.println("Analysing Normalized Difference Scores...");

		try {

			// This will keep the information gain extracted from each hash
			HashMap<String, Double> hashesWithIG = new HashMap<String, Double>();

			int topRankedSize = Integer.parseInt(FileHandler
					.readConfigValue(Constants.TOP_RANKED_SIZE_CONFIG));

			// This structure will keep the top-ranked hashes with their
			// information gain
			ScorePair[] topRankedHashes = new ScorePair[topRankedSize];
			// This structure is defined to validate the distribution of
			// information gain scores
			ScorePair[] randomHashes = new ScorePair[topRankedSize];

			// Retrieve the number of apps per class from the specific entry
			Short[] countApps = hashes.get(Constants.COUNT_OF_APPS_PER_CLASS);
			double totalNumberOfAppsInClassA = (double) countApps[0];// 10
			double totalNumberOfAppsInClassB = (double) countApps[1];// 10

			// Remove this specific entry not to interpret as hash
			// hashes.remove(Constants.TOTAL_COUNT_OF_APPS_FOR_CLASSES);

			// Iterate hash hashmap to calculate information gain for each
			// hash
			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {

				// Calculate the number of apps for each classes that owns the
				// given hash

				Short[] values = entry.getValue();

				double frequencyOfHashInClassA = (double) values[0];
				double frequencyOfHashInClassB = (double) values[1];

				double probabilityOfHashInClassA = (double) values[0]
						/ totalNumberOfAppsInClassA;
				double probabilityOfHashInClassB = (double) values[1]
						/ totalNumberOfAppsInClassB;

				// (|(p_B-p_M)/(p_B+p_M)*log(f_B+f_M)|)
				double differenceScore = Math
						.abs((probabilityOfHashInClassA - probabilityOfHashInClassB)
								/ (probabilityOfHashInClassA + probabilityOfHashInClassB)
								* Math.log(frequencyOfHashInClassA
										+ frequencyOfHashInClassB));

				hashesWithIG.put(entry.getKey(), differenceScore);
			}

			// Initialize top-ranked array values for ordering and comparison
			for (int i = 0; i < topRankedHashes.length; i++) {
				topRankedHashes[i] = new ScorePair(Integer.toString(i), 0.0);
				randomHashes[i] = new ScorePair(Integer.toString(i), 0.0);
			}

			for (Map.Entry<String, Double> entry : hashesWithIG.entrySet()) {

				// Find the first minimum value and its index in top-ranked
				// array to replace-> index0:index of the item, index 1-> value
				// of item
				double[] minIG = minIndexAndValue(topRankedHashes);
				if (entry.getValue() > minIG[1]) {
					topRankedHashes[(int) minIG[0]] = new ScorePair(
							entry.getKey(), entry.getValue());
				}

				// If there is positive number add this value to the array with
				// random index to validate distribution
				if (entry.getValue() > 0.0) {
					randomHashes[randWithinRange(0, topRankedSize - 1)] = new ScorePair(
							entry.getKey(), entry.getValue());
				}
			}
			// Sort top ranked array and print it to file and console
			Arrays.sort(topRankedHashes);
			FileUtils.write(rankedHashesFile, "Rank" + Constants.TAB_CHAR
					+ "String" + Constants.TAB_CHAR + "Difference Score"
					+ Constants.TAB_CHAR + "Hash" + "\n", true);
			System.out.print("Rank" + Constants.TAB_CHAR + "String"
					+ Constants.TAB_CHAR + "Difference Score"
					+ Constants.TAB_CHAR + "Hash" + "\n");
			for (int i = 0; i < topRankedHashes.length; i++) {
				String md5 = new String(DigestUtils.md5Hex(topRankedHashes[i]
						.getKey()));

				System.out.print((i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n");
				FileUtils.write(rankedHashesFile, (i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n", true);
			}
			watch.stop();
			// Print the time elapsed to analyze the app.
			System.out.println("Analysis is finisihed...Elapsed Time:"
					+ (double) watch.getTime() / 1000.0 + " secs." + "\n");

		} catch (Exception e) {
			e.printStackTrace();
		}
		return rankedHashesFile.getAbsolutePath();
	}

	public static String extractDistinctiveHashesByNormalizedDistance(
			HashMap<String, Short[]> hashes, String extension) {
		// Top-ranked hash features file name generation
		String signatureType = FileHandler
				.readConfigValue(Constants.SIGNATURE_ENTITY_TYPE);

		String rankedHashesPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ (extension + Constants.UNDERSCORE + "distinctive"
						+ Constants.UNDERSCORE + signatureType
						+ Constants.UNDERSCORE + "by_distance.tsv")
						.toLowerCase();
		File rankedHashesFile = new File(rankedHashesPath);
		StopWatch watch = new StopWatch();
		watch.reset();
		watch.start();

		// Try to delete if it exists without exception
		FileUtils.deleteQuietly(rankedHashesFile);
		System.out.println("Analysing Normalized Distance Scores...");

		try {

			// This will keep the information gain extracted from each hash
			HashMap<String, Double> hashesWithIG = new HashMap<String, Double>();

			int topRankedSize = Integer.parseInt(FileHandler
					.readConfigValue(Constants.TOP_RANKED_SIZE_CONFIG));

			// This structure will keep the top-ranked hashes with their
			// information gain
			ScorePair[] topRankedHashes = new ScorePair[topRankedSize];
			// This structure is defined to validate the distribution of
			// information gain scores
			ScorePair[] randomHashes = new ScorePair[topRankedSize];

			// Retrieve the number of apps per class from the specific entry
			Short[] countApps = hashes.get(Constants.COUNT_OF_APPS_PER_CLASS);
			double totalNumberOfAppsInClassA = (double) countApps[0];// 10
			double totalNumberOfAppsInClassB = (double) countApps[1];// 10

			// ax+by+c, c=0,b=-1
			double a = totalNumberOfAppsInClassB / totalNumberOfAppsInClassB;
			double b = -1.0;

			// Remove this specific entry not to interpret as hash
			// hashes.remove(Constants.TOTAL_COUNT_OF_APPS_FOR_CLASSES);

			// Iterate hash hashmap to calculate information gain for each
			// hash
			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {

				// Calculate the number of apps for each classes that owns the
				// given hash

				Short[] values = entry.getValue();

				// Terms that are needed for information gain calculation
				double probabilityOfHashInClassA = (double) values[0]
						/ totalNumberOfAppsInClassA;
				double probabilityOfHashInClassB = (double) values[1]
						/ totalNumberOfAppsInClassB;
				double probabilityOfHash = probabilityOfHashInClassA
						+ probabilityOfHashInClassB;

				// log(p(ngram))xdistance
				// Calculation formula of normalized distances
				double distanceScore = Math.abs(Math.log(probabilityOfHash)
						* ((a * probabilityOfHashInClassA + b
								* probabilityOfHashInClassB) / Math.sqrt(Math
								.pow(a, 2) + Math.pow(b, 2))));

				// Add calculated information gain for the given hash
				hashesWithIG.put(entry.getKey(), distanceScore);
			}

			// Initialize top-ranked array values for ordering and comparison
			for (int i = 0; i < topRankedHashes.length; i++) {
				topRankedHashes[i] = new ScorePair(Integer.toString(i), 0.0);
				randomHashes[i] = new ScorePair(Integer.toString(i), 0.0);
			}

			for (Map.Entry<String, Double> entry : hashesWithIG.entrySet()) {

				// Find the first minimum value and its index in top-ranked
				// array to replace-> index0:index of the item, index 1-> value
				// of item
				double[] minIG = minIndexAndValue(topRankedHashes);
				if (entry.getValue() > minIG[1]) {
					topRankedHashes[(int) minIG[0]] = new ScorePair(
							entry.getKey(), entry.getValue());
				}

				// If there is positive number add this value to the array with
				// random index to validate distribution
				if (entry.getValue() > 0.0) {
					randomHashes[randWithinRange(0, topRankedSize - 1)] = new ScorePair(
							entry.getKey(), entry.getValue());
				}
			}
			// Sort top ranked array and print it to file and console
			Arrays.sort(topRankedHashes);
			FileUtils.write(rankedHashesFile, "Rank" + Constants.TAB_CHAR
					+ "String" + Constants.TAB_CHAR + "Distance Score"
					+ Constants.TAB_CHAR + "Hash" + "\n", true);
			System.out.print("Rank" + Constants.TAB_CHAR + "String"
					+ Constants.TAB_CHAR + "Distance Score"
					+ Constants.TAB_CHAR + "Hash" + "\n");
			for (int i = 0; i < topRankedHashes.length; i++) {
				String md5 = new String(DigestUtils.md5Hex(topRankedHashes[i]
						.getKey()));

				System.out.print((i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n");
				FileUtils.write(rankedHashesFile, (i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n", true);
			}
			watch.stop();
			// Print the time elapsed to analyze the app.
			System.out.println("Analysis is finisihed...Elapsed Time:"
					+ (double) watch.getTime() / 1000.0 + " secs." + "\n");

		} catch (Exception e) {
			e.printStackTrace();
		}
		return rankedHashesFile.getAbsolutePath();
	}

	public static String extractDistinctiveHashesByNormalizedDistanceRatio(
			HashMap<String, Short[]> hashes, String extension) {
		// Top-ranked hash features file name generation
		String signatureType = FileHandler
				.readConfigValue(Constants.SIGNATURE_ENTITY_TYPE);

		String rankedHashesPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ (extension + Constants.UNDERSCORE + "distinctive"
						+ Constants.UNDERSCORE + signatureType
						+ Constants.UNDERSCORE + "by_distance_ratio.tsv")
						.toLowerCase();
		File rankedHashesFile = new File(rankedHashesPath);
		StopWatch watch = new StopWatch();
		watch.reset();
		watch.start();

		// Try to delete if it exists without exception
		FileUtils.deleteQuietly(rankedHashesFile);
		System.out.println("Analysing Normalized Distance Ratio Scores...");

		try {

			// This will keep the information gain extracted from each hash
			HashMap<String, Double> hashesWithIG = new HashMap<String, Double>();

			int topRankedSize = Integer.parseInt(FileHandler
					.readConfigValue(Constants.TOP_RANKED_SIZE_CONFIG));

			// This structure will keep the top-ranked hashes with their
			// information gain
			ScorePair[] topRankedHashes = new ScorePair[topRankedSize];
			// This structure is defined to validate the distribution of
			// information gain scores
			ScorePair[] randomHashes = new ScorePair[topRankedSize];

			// Retrieve the number of apps per class from the specific entry
			Short[] countApps = hashes.get(Constants.COUNT_OF_APPS_PER_CLASS);
			double totalNumberOfAppsInClassA = (double) countApps[0];// 10
			double totalNumberOfAppsInClassB = (double) countApps[1];// 10

			// Remove this specific entry not to interpret as hash
			// hashes.remove(Constants.TOTAL_COUNT_OF_APPS_FOR_CLASSES);

			// Iterate hash hashmap to calculate information gain for each
			// hash
			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {

				// Calculate the number of apps for each classes that owns the
				// given hash

				Short[] values = entry.getValue();

				// Terms that are needed for information gain calculation
				double probabilityOfHashInClassA = (double) values[0]
						/ totalNumberOfAppsInClassA;
				double probabilityOfHashInClassB = (double) values[1]
						/ totalNumberOfAppsInClassB;
				double probabilityOfHypotenuse = Math.sqrt(Math.pow(
						probabilityOfHashInClassA, 2.0)
						+ Math.pow(probabilityOfHashInClassB, 2.0));
				double normalizer = Math.log(probabilityOfHypotenuse);

				// log(p(ngram))xdistance
				// Calculation formula of normalized distances
				double distanceRatioScore = Math.abs(normalizer
						* Math.sqrt(Math.pow(probabilityOfHashInClassA
								- probabilityOfHashInClassB, 2)
								+ Math.pow(probabilityOfHashInClassB
										- probabilityOfHashInClassA, 2))
						/ Math.sqrt(probabilityOfHypotenuse)

				);

				// Add calculated information gain for the given hash
				hashesWithIG.put(entry.getKey(), distanceRatioScore);
			}

			// Initialize top-ranked array values for ordering and comparison
			for (int i = 0; i < topRankedHashes.length; i++) {
				topRankedHashes[i] = new ScorePair(Integer.toString(i), 0.0);
				randomHashes[i] = new ScorePair(Integer.toString(i), 0.0);
			}

			for (Map.Entry<String, Double> entry : hashesWithIG.entrySet()) {

				// Find the first minimum value and its index in top-ranked
				// array to replace-> index0:index of the item, index 1-> value
				// of item
				double[] minIG = minIndexAndValue(topRankedHashes);
				if (entry.getValue() > minIG[1]) {
					topRankedHashes[(int) minIG[0]] = new ScorePair(
							entry.getKey(), entry.getValue());
				}

				// If there is positive number add this value to the array with
				// random index to validate distribution
				if (entry.getValue() > 0.0) {
					randomHashes[randWithinRange(0, topRankedSize - 1)] = new ScorePair(
							entry.getKey(), entry.getValue());
				}
			}
			// Sort top ranked array and print it to file and console
			Arrays.sort(topRankedHashes);
			FileUtils.write(rankedHashesFile, "Rank" + Constants.TAB_CHAR
					+ "String" + Constants.TAB_CHAR + "Distance Score"
					+ Constants.TAB_CHAR + "Hash" + "\n", true);
			System.out.print("Rank" + Constants.TAB_CHAR + "String"
					+ Constants.TAB_CHAR + "Distance Score"
					+ Constants.TAB_CHAR + "Hash" + "\n");
			for (int i = 0; i < topRankedHashes.length; i++) {
				String md5 = new String(DigestUtils.md5Hex(topRankedHashes[i]
						.getKey()));

				System.out.print((i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n");
				FileUtils.write(rankedHashesFile, (i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n", true);
			}
			watch.stop();
			// Print the time elapsed to analyze the app.
			System.out.println("Analysis is finisihed...Elapsed Time:"
					+ (double) watch.getTime() / 1000.0 + " secs." + "\n");

		} catch (Exception e) {
			e.printStackTrace();
		}
		return rankedHashesFile.getAbsolutePath();
	}


	public static String extractDistinctiveHashesByNormalizedAngle(
			HashMap<String, Short[]> hashes, String extension) {
		// Top-ranked hash features file name generation
		String signatureType = FileHandler
				.readConfigValue(Constants.SIGNATURE_ENTITY_TYPE);

		String rankedHashesPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ (extension + Constants.UNDERSCORE + "distinctive"
						+ Constants.UNDERSCORE + signatureType
						+ Constants.UNDERSCORE + "by_sin.tsv")
						.toLowerCase();
		File rankedHashesFile = new File(rankedHashesPath);
		StopWatch watch = new StopWatch();
		watch.reset();
		watch.start();

		// Try to delete if it exists without exception
		FileUtils.deleteQuietly(rankedHashesFile);
		System.out.println("Analysing Normalized Sin Scores...");

		try {

			// This will keep the information gain extracted from each hash
			HashMap<String, Double> hashesWithIG = new HashMap<String, Double>();

			int topRankedSize = Integer.parseInt(FileHandler
					.readConfigValue(Constants.TOP_RANKED_SIZE_CONFIG));

			// This structure will keep the top-ranked hashes with their
			// information gain
			ScorePair[] topRankedHashes = new ScorePair[topRankedSize];
			// This structure is defined to validate the distribution of
			// information gain scores
			ScorePair[] randomHashes = new ScorePair[topRankedSize];

			// Retrieve the number of apps per class from the specific entry
			Short[] countApps = hashes.get(Constants.COUNT_OF_APPS_PER_CLASS);
			double totalNumberOfAppsInClassA = (double) countApps[0];// 10
			double totalNumberOfAppsInClassB = (double) countApps[1];// 10

			// Remove this specific entry not to interpret as hash
			// hashes.remove(Constants.TOTAL_COUNT_OF_APPS_FOR_CLASSES);

			// Iterate hash hashmap to calculate information gain for each
			// hash
			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {

				// Calculate the number of apps for each classes that owns the
				// given hash

				Short[] values = entry.getValue();

				// Terms that are needed for information gain calculation
				double probabilityOfHashInClassA = (double) values[0]
						/ totalNumberOfAppsInClassA;
				double probabilityOfHashInClassB = (double) values[1]
						/ totalNumberOfAppsInClassB;
				double probabilityOfHypotenuse = Math.sqrt(Math.pow(
						probabilityOfHashInClassA, 2.0)
						+ Math.pow(probabilityOfHashInClassB, 2.0));
				
				double absDiff = Math.abs(probabilityOfHashInClassA-probabilityOfHashInClassB);
				double sinOfAngle = Math.sqrt(Math.pow(probabilityOfHashInClassA-probabilityOfHashInClassB, 2.0)+Math.pow(probabilityOfHashInClassB-probabilityOfHashInClassA, 2.0))/(2*probabilityOfHypotenuse);
				double angleUnit = Math.asin(sinOfAngle)/(Math.PI/4); //45=1 0=0
				double normalizer = Math.sqrt(absDiff);

				double distanceRatioScore = normalizer*angleUnit;
				// Add calculated information gain for the given hash
				hashesWithIG.put(entry.getKey(), distanceRatioScore);
			}

			// Initialize top-ranked array values for ordering and comparison
			for (int i = 0; i < topRankedHashes.length; i++) {
				topRankedHashes[i] = new ScorePair(Integer.toString(i), 0.0);
				randomHashes[i] = new ScorePair(Integer.toString(i), 0.0);
			}

			for (Map.Entry<String, Double> entry : hashesWithIG.entrySet()) {

				// Find the first minimum value and its index in top-ranked
				// array to replace-> index0:index of the item, index 1-> value
				// of item
				double[] minIG = minIndexAndValue(topRankedHashes);
				if (entry.getValue() > minIG[1]) {
					topRankedHashes[(int) minIG[0]] = new ScorePair(
							entry.getKey(), entry.getValue());
				}

				// If there is positive number add this value to the array with
				// random index to validate distribution
				if (entry.getValue() > 0.0) {
					randomHashes[randWithinRange(0, topRankedSize - 1)] = new ScorePair(
							entry.getKey(), entry.getValue());
				}
			}
			// Sort top ranked array and print it to file and console
			Arrays.sort(topRankedHashes);
			FileUtils.write(rankedHashesFile, "Rank" + Constants.TAB_CHAR
					+ "String" + Constants.TAB_CHAR + "Distance Score"
					+ Constants.TAB_CHAR + "Hash" + "\n", true);
			System.out.print("Rank" + Constants.TAB_CHAR + "String"
					+ Constants.TAB_CHAR + "Distance Score"
					+ Constants.TAB_CHAR + "Hash" + "\n");
			for (int i = 0; i < topRankedHashes.length; i++) {
				String md5 = new String(DigestUtils.md5Hex(topRankedHashes[i]
						.getKey()));

				System.out.print((i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n");
				FileUtils.write(rankedHashesFile, (i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n", true);
			}
			watch.stop();
			// Print the time elapsed to analyze the app.
			System.out.println("Analysis is finisihed...Elapsed Time:"
					+ (double) watch.getTime() / 1000.0 + " secs." + "\n");

		} catch (Exception e) {
			e.printStackTrace();
		}
		return rankedHashesFile.getAbsolutePath();
	}

	public static String extractDistinctiveHashesByIG(
			HashMap<String, Short[]> hashes, String extension) {
		// Top-ranked hash features file name generation
		String signatureType = FileHandler
				.readConfigValue(Constants.SIGNATURE_ENTITY_TYPE);

		String rankedHashesPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ (extension + Constants.UNDERSCORE + "distinctive"
						+ Constants.UNDERSCORE + signatureType
						+ Constants.UNDERSCORE + "by_ig.tsv").toLowerCase();
		File rankedHashesFile = new File(rankedHashesPath);
		StopWatch watch = new StopWatch();
		watch.reset();
		watch.start();

		// Try to delete if it exists without exception
		FileUtils.deleteQuietly(rankedHashesFile);
		System.out.println("Analysing Information Gain Scores...");
		try {

			// This will keep the information gain extracted from each hash
			HashMap<String, Double> hashesWithIG = new HashMap<String, Double>();

			int topRankedSize = Integer.parseInt(FileHandler
					.readConfigValue(Constants.TOP_RANKED_SIZE_CONFIG));

			// This structure will keep the top-ranked hashes with their
			// information gain
			ScorePair[] topRankedHashes = new ScorePair[topRankedSize];
			// This structure is defined to validate the distribution of
			// information gain scores
			ScorePair[] randomHashes = new ScorePair[topRankedSize];

			// Retrieve the number of apps per class from the specific entry
			Short[] countApps = hashes.get(Constants.COUNT_OF_APPS_PER_CLASS);
			double totalNumberOfAppsInClassA = (double) countApps[0];// 10
			double totalNumberOfAppsInClassB = (double) countApps[1];// 10
			double totalNumberOfApps = (double) (totalNumberOfAppsInClassA + totalNumberOfAppsInClassB);

			// Remove this specific entry not to interpret as hash
			// hashes.remove(Constants.TOTAL_COUNT_OF_APPS_FOR_CLASSES);

			// Iterate hash hashmap to calculate information gain for each
			// hash
			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {

				// Calculate the number of apps for each classes that owns the
				// given hash
				Short[] values = entry.getValue();

				// Terms that are needed for information gain calculation
				double numberOfAppsHoldHashInClassA = (double) values[0];
				double numberOfAppsDoNotHoldHashInClassA = (double) (totalNumberOfAppsInClassA - values[0]);
				double numberOfAppsHoldHashInClassB = (double) values[1];
				double numberOfAppsDoNotHoldHashInClassB = (double) (totalNumberOfAppsInClassB - values[1]);

				// Calculation formula of information gain: For details see the
				// paper of Kolter et. al and Reddy et. al.
				double[] informationGainForHash = new double[4];
				informationGainForHash[0] = (numberOfAppsHoldHashInClassA / totalNumberOfAppsInClassA)
						* Math.log((numberOfAppsHoldHashInClassA / totalNumberOfAppsInClassA)
								/ (((numberOfAppsHoldHashInClassA + numberOfAppsHoldHashInClassB) / totalNumberOfApps) * (totalNumberOfAppsInClassA / totalNumberOfApps)));

				informationGainForHash[1] = (numberOfAppsDoNotHoldHashInClassA / totalNumberOfAppsInClassA)
						* Math.log((numberOfAppsDoNotHoldHashInClassA / totalNumberOfAppsInClassA)
								/ (((numberOfAppsDoNotHoldHashInClassA + numberOfAppsDoNotHoldHashInClassB) / totalNumberOfApps) * (totalNumberOfAppsInClassA / totalNumberOfApps)));

				informationGainForHash[2] = (numberOfAppsHoldHashInClassB / totalNumberOfAppsInClassB)
						* Math.log((numberOfAppsHoldHashInClassB / totalNumberOfAppsInClassB)
								/ (((numberOfAppsHoldHashInClassA + numberOfAppsHoldHashInClassB) / totalNumberOfApps) * (totalNumberOfAppsInClassB / totalNumberOfApps)));

				informationGainForHash[3] = (numberOfAppsDoNotHoldHashInClassB / totalNumberOfAppsInClassB)
						* Math.log((numberOfAppsDoNotHoldHashInClassB / totalNumberOfAppsInClassB)
								/ (((numberOfAppsDoNotHoldHashInClassA + numberOfAppsDoNotHoldHashInClassB) / totalNumberOfApps) * (totalNumberOfAppsInClassB / totalNumberOfApps)));

				// Skip infinite and NaN terms
				double informationGainForHashTotal = 0.0;
				for (int i = 0; i < informationGainForHash.length; i++) {
					if (!(Double.isNaN(informationGainForHash[i]) || !Double
							.isFinite(informationGainForHash[i]))) {
						informationGainForHashTotal += informationGainForHash[i];
					}
				}
				// Add calculated information gain for the given hash
				hashesWithIG.put(entry.getKey(), informationGainForHashTotal);
			}

			// Initialize top-ranked array values for ordering and comparison
			for (int i = 0; i < topRankedHashes.length; i++) {
				topRankedHashes[i] = new ScorePair(Integer.toString(i), 0.0);
				randomHashes[i] = new ScorePair(Integer.toString(i), 0.0);
			}

			for (Map.Entry<String, Double> entry : hashesWithIG.entrySet()) {

				// Find the first minimum value and its index in top-ranked
				// array to replace-> index0:index of the item, index 1-> value
				// of item
				double[] minIG = minIndexAndValue(topRankedHashes);
				if (entry.getValue() > minIG[1]) {
					topRankedHashes[(int) minIG[0]] = new ScorePair(
							entry.getKey(), entry.getValue());
				}

				// If there is positive number add this value to the array with
				// random index to validate distribution
				if (entry.getValue() > 0.0) {
					randomHashes[randWithinRange(0, topRankedSize - 1)] = new ScorePair(
							entry.getKey(), entry.getValue());
				}
			}
			// Sort top ranked array and print it to file and console
			Arrays.sort(topRankedHashes);
			FileUtils.write(rankedHashesFile, "Rank" + Constants.TAB_CHAR
					+ "String" + Constants.TAB_CHAR + "Information Gain"
					+ Constants.TAB_CHAR + "Hash" + "\n", true);
			System.out.print("Rank" + Constants.TAB_CHAR + "String"
					+ Constants.TAB_CHAR + "Information Gain"
					+ Constants.TAB_CHAR + "Hash" + "\n");
			for (int i = 0; i < topRankedHashes.length; i++) {
				String md5 = new String(DigestUtils.md5Hex(topRankedHashes[i]
						.getKey()));

				System.out.print((i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n");
				FileUtils.write(rankedHashesFile, (i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + Constants.TAB_CHAR
						+ md5 + "\n", true);
			}
			watch.stop();
			// Print the time elapsed to analyze the app.
			System.out.println("Analysis is finished... Elapsed Time:"
					+ (double) watch.getTime() / 1000.0 + " secs." + "\n");

		} catch (Exception e) {
			e.printStackTrace();
		}
		return rankedHashesFile.getAbsolutePath();
	}

	public static String extractDistinctiveHashesByClasswiseIG(
			HashMap<String, Short[]> hashes, String extension) {
		// Top-ranked hash features file name generation
		String signatureType = FileHandler
				.readConfigValue(Constants.SIGNATURE_ENTITY_TYPE);

		String rankedHashesPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ (extension + Constants.UNDERSCORE + "distinctive"
						+ Constants.UNDERSCORE + signatureType
						+ Constants.UNDERSCORE + "by_classwise_ig.tsv")
						.toLowerCase();
		File rankedHashesFile = new File(rankedHashesPath);
		StopWatch watch = new StopWatch();
		watch.reset();
		watch.start();

		// Try to delete if it exists without exception
		FileUtils.deleteQuietly(rankedHashesFile);
		System.out.println("Analysing Classwise Information Gain Scores...");
		try {

			// This will keep the information gain extracted from each hash
			HashMap<String, Double> hashesWithIG = new HashMap<String, Double>();

			int topRankedSize = Integer.parseInt(FileHandler
					.readConfigValue(Constants.TOP_RANKED_SIZE_CONFIG));
			// This structure will keep the top-ranked hashes with their
			// information gain
			ScorePair[] topRankedHashes = new ScorePair[topRankedSize];
			ScorePair[] topRankedHashesForClassA = new ScorePair[topRankedSize / 2];
			ScorePair[] topRankedHashesForClassB = new ScorePair[topRankedSize / 2];

			// This structure is defined to validate the distribution of
			// information gain scores
			ScorePair[] randomHashes = new ScorePair[topRankedSize];

			// Retrieve the number of apps per class from the specific entry
			Short[] countApps = hashes.get(Constants.COUNT_OF_APPS_PER_CLASS);
			double totalNumberOfAppsInClassA = (double) countApps[0];// 10
			double totalNumberOfAppsInClassB = (double) countApps[1];// 10
			double totalNumberOfApps = (double) (totalNumberOfAppsInClassA + totalNumberOfAppsInClassB);

			// Remove this specific entry not to interpret as hash
			// hashes.remove(Constants.TOTAL_COUNT_OF_APPS_FOR_CLASSES);

			// Iterate hash hashmap to calculate information gain for each
			// hash
			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {

				// Calculate the number of apps for each classes that owns the
				// given hash
				Short[] values = entry.getValue();

				// Terms that are needed for information gain calculation
				double numberOfAppsHoldHashInClassA = (double) values[0];
				double numberOfAppsDoNotHoldHashInClassA = (double) (totalNumberOfAppsInClassA - values[0]);
				double numberOfAppsHoldHashInClassB = (double) values[1];
				double numberOfAppsDoNotHoldHashInClassB = (double) (totalNumberOfAppsInClassB - values[1]);

				// Calculation formula of information gain: For details see the
				// paper of Kolter et. al and Reddy et. al.
				double[] informationGainForHash = new double[4];
				informationGainForHash[0] = (numberOfAppsHoldHashInClassA / totalNumberOfAppsInClassA)
						* Math.log((numberOfAppsHoldHashInClassA / totalNumberOfAppsInClassA)
								/ (((numberOfAppsHoldHashInClassA + numberOfAppsHoldHashInClassB) / totalNumberOfApps) * (totalNumberOfAppsInClassA / totalNumberOfApps)));

				informationGainForHash[1] = (numberOfAppsDoNotHoldHashInClassA / totalNumberOfAppsInClassA)
						* Math.log((numberOfAppsDoNotHoldHashInClassA / totalNumberOfAppsInClassA)
								/ (((numberOfAppsDoNotHoldHashInClassA + numberOfAppsDoNotHoldHashInClassB) / totalNumberOfApps) * (totalNumberOfAppsInClassA / totalNumberOfApps)));

				informationGainForHash[2] = (numberOfAppsHoldHashInClassB / totalNumberOfAppsInClassB)
						* Math.log((numberOfAppsHoldHashInClassB / totalNumberOfAppsInClassB)
								/ (((numberOfAppsHoldHashInClassA + numberOfAppsHoldHashInClassB) / totalNumberOfApps) * (totalNumberOfAppsInClassB / totalNumberOfApps)));

				informationGainForHash[3] = (numberOfAppsDoNotHoldHashInClassB / totalNumberOfAppsInClassB)
						* Math.log((numberOfAppsDoNotHoldHashInClassB / totalNumberOfAppsInClassB)
								/ (((numberOfAppsDoNotHoldHashInClassA + numberOfAppsDoNotHoldHashInClassB) / totalNumberOfApps) * (totalNumberOfAppsInClassB / totalNumberOfApps)));

				// Skip infinite and NaN terms
				double informationGainForHashTotal = 0.0;
				for (int i = 0; i < informationGainForHash.length; i++) {
					if (!(Double.isNaN(informationGainForHash[i]) || !Double
							.isFinite(informationGainForHash[i]))) {
						informationGainForHashTotal += informationGainForHash[i];
					}
				}
				// Add calculated information gain for the given hash
				hashesWithIG.put(entry.getKey(), informationGainForHashTotal);
			}

			// Initialize top-ranked array values for ordering and comparison
			for (int i = 0; i < topRankedSize / 2; i++) {
				topRankedHashesForClassA[i] = new ScorePair(
						Integer.toString(i), 0.0);
				topRankedHashesForClassB[i] = new ScorePair(
						Integer.toString(i), 0.0);
			}

			for (int i = 0; i < topRankedSize; i++) {
				topRankedHashes[i] = new ScorePair(Integer.toString(i), 0.0);
				randomHashes[i] = new ScorePair(Integer.toString(i), 0.0);
			}
			boolean taxon = true;
			for (Map.Entry<String, Double> entry : hashesWithIG.entrySet()) {

				// Find the first minimum value and its index in top-ranked
				// array to replace-> index0:index of the item, index 1-> value
				// of item
				double[] minIGA = minIndexAndValue(topRankedHashesForClassA);
				double[] minIGB = minIndexAndValue(topRankedHashesForClassB);

				Short[] counts = hashes.get(entry.getKey());
				taxon = (((double) counts[0] / totalNumberOfAppsInClassA) >= ((double) counts[1] / totalNumberOfAppsInClassB));

				if (taxon) {
					if (entry.getValue() > minIGA[1]) {
						topRankedHashesForClassA[(int) minIGA[0]] = new ScorePair(
								entry.getKey(), entry.getValue());
					}
				} else {
					if (entry.getValue() > minIGB[1]) {
						topRankedHashesForClassB[(int) minIGB[0]] = new ScorePair(
								entry.getKey(), entry.getValue());
					}
				}

				// If there is positive number add this value to the array with
				// random index to validate distribution
				if (entry.getValue() > 0.0) {
					randomHashes[randWithinRange(0, topRankedSize - 1)] = new ScorePair(
							entry.getKey(), entry.getValue());
				}
			}
			// Sort top ranked array and print it to file and console
			Arrays.sort(topRankedHashesForClassA);
			Arrays.sort(topRankedHashesForClassB);
			int index = 0;
			int indexClass = 0;
			while (index < topRankedHashes.length) {
				topRankedHashes[index] = topRankedHashesForClassA[indexClass];
				topRankedHashes[++index] = topRankedHashesForClassB[indexClass];
				index++;
				indexClass++;
			}
			FileUtils.write(rankedHashesFile, "Rank" + Constants.TAB_CHAR
					+ "String" + Constants.TAB_CHAR + "Information Gain"
					+ Constants.TAB_CHAR + "Class" + Constants.TAB_CHAR
					+ "Hash" + "\n", true);
			System.out.print("Rank" + Constants.TAB_CHAR + "String"
					+ Constants.TAB_CHAR + "Information Gain"
					+ Constants.TAB_CHAR + "Class" + Constants.TAB_CHAR
					+ "Hash" + "\n");
			for (int i = 0; i < topRankedHashes.length; i++) {
				String md5 = new String(DigestUtils.md5Hex(topRankedHashes[i]
						.getKey()));
				System.out.print((i + 1)
						+ Constants.TAB_CHAR
						+ topRankedHashes[i].getKey()
						+ Constants.TAB_CHAR
						+ topRankedHashes[i].getValue()
						+ Constants.TAB_CHAR
						+ (((i % 2) == 0) ? Constants.CLASS_A_NAME
								: Constants.CLASS_B_NAME) + Constants.TAB_CHAR
						+ md5 + "\n");
				FileUtils.write(rankedHashesFile, (i + 1)
						+ Constants.TAB_CHAR
						+ topRankedHashes[i].getKey()
						+ Constants.TAB_CHAR
						+ topRankedHashes[i].getValue()
						+ Constants.TAB_CHAR
						+ (((i % 2) == 0) ? Constants.CLASS_A_NAME
								: Constants.CLASS_B_NAME) + Constants.TAB_CHAR
						+ md5 + "\n", true);
			}
			watch.stop();
			// Print the time elapsed to analyze the app.
			System.out.println("Analysis is finished...Elapsed Time:"
					+ (double) watch.getTime() / 1000.0 + " secs." + "\n");

		} catch (Exception e) {
			e.printStackTrace();
		}
		return rankedHashesFile.getAbsolutePath();
	}

	public static void printFrequenciesOfHashes(
			HashMap<String, Short[]> hashes, String signatureType) {
		String hashesFrequenciesPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ ("frequencies" + Constants.UNDERSCORE + signatureType + ".tsv")
						.toLowerCase();
		File hashesFrequenciesFile = new File(hashesFrequenciesPath);

		// Try to delete if it exists without exception
		FileUtils.deleteQuietly(hashesFrequenciesFile);
		try {
			FileUtils.write(hashesFrequenciesFile, "Entity"
					+ Constants.TAB_CHAR + "Benign" + Constants.TAB_CHAR
					+ "Malware", true);
			System.out.print("Entity" + Constants.TAB_CHAR + "Benign"
					+ Constants.TAB_CHAR + "Malware");

			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {

				// Calculate the number of apps for each classes that owns the

				Short[] values = entry.getValue();
				System.out.print("\n" + entry.getKey() + Constants.TAB_CHAR
						+ values[0] + Constants.TAB_CHAR + values[1]);

				FileUtils.write(hashesFrequenciesFile, "\n" + entry.getKey()
						+ Constants.TAB_CHAR + values[0] + Constants.TAB_CHAR
						+ values[1], true);

			}

		} catch (Exception e) {
			e.printStackTrace();
		}
	}

	public static HashMap<String, Double[]> calculateCondProbsOfHashes(
			HashMap<String, Short[]> hashes, String signatureType) {
		String hashesCondProbPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ ("cond_probs_of" + Constants.UNDERSCORE + signatureType + ".tsv")
						.toLowerCase();
		File hashesCondProbFile = new File(hashesCondProbPath);

		// Try to delete if it exists without exception
		FileUtils.deleteQuietly(hashesCondProbFile);
		// This will keep the conditional probabilities of each hash for each
		// class: P(g|S_i)
		HashMap<String, Double[]> hashesWithCondProbs = new HashMap<String, Double[]>();

		try {

			// Retrieve the number of apps for each class
			Short[] appCountPerClass = hashes
					.get(Constants.COUNT_OF_APPS_PER_CLASS);

			int numberOfClass = appCountPerClass.length;

			double[] totalNumberOfAppsInClass = new double[appCountPerClass.length];
			double totalNumberOfApps = 0.0;
			for (int i = 0; i < appCountPerClass.length; i++) {
				totalNumberOfAppsInClass[i] = (double) appCountPerClass[i];
				totalNumberOfApps += totalNumberOfAppsInClass[i];
			}
			// Calculate prior probability for each class: P(C_i)
			Double[] priors = new Double[numberOfClass];
			for (int i = 0; i < priors.length; i++)
				priors[i] = totalNumberOfAppsInClass[i] / totalNumberOfApps;

			hashesWithCondProbs.put(Constants.PRIOR_PER_CLASS, priors);

			// Retrieve the number of hashes for each class
			Integer[] hashCountPerClass = new Integer[] { 0, 0 };

			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {
				hashCountPerClass[0] += entry.getValue()[0];
				hashCountPerClass[1] += entry.getValue()[1];
			}
			int vocabularySize = hashes.size();
			// Iterate hash hashmap to calculate conditional probabilities for
			// each hash
			for (Map.Entry<String, Short[]> entry : hashes.entrySet()) {

				// Calculate the number of apps for each classes that owns the
				// given hash
				Double[] condProbs = new Double[numberOfClass];

				Short[] values = entry.getValue();

				for (int i = 0; i < numberOfClass; i++)
					condProbs[i] = (((double) values[i] + 1.0) / ((double) hashCountPerClass[i] + (double) vocabularySize));

				hashesWithCondProbs.put(entry.getKey(), condProbs);

			}

			FileUtils.write(hashesCondProbFile, "HASH" + Constants.TAB_CHAR
					+ "CONDITIONAL PROBABILITES", true);

			for (Map.Entry<String, Double[]> entry : hashesWithCondProbs
					.entrySet()) {
				FileUtils
						.write(hashesCondProbFile, "\n" + entry.getKey(), true);

				for (int i = 0; i < numberOfClass; i++) {
					FileUtils.write(hashesCondProbFile, Constants.TAB_CHAR
							+ entry.getValue()[i], true);
				}
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
		return hashesWithCondProbs;
	}

	public static HashMap<String, Double[]> readCondProbsOfHashesFromFile(
			String filePath) {

		File hashesCondProbFile = new File(filePath);
		// This will keep the conditional probabilities of each hash for each
		// class: P(g|C_i)
		HashMap<String, Double[]> hashesWithCondProbs = new HashMap<String, Double[]>();

		try {
			List<String> lines = FileUtils.readLines(hashesCondProbFile);
			int lineNumber = 0;
			for (String line : lines) {
				lineNumber++;
				// Skip header line
				if (line != null && !line.equals("") && lineNumber != 1) {
					String[] tokens = line.split(Constants.TAB_CHAR);
					Double[] probs = new Double[tokens.length - 1];
					for (int i = 0; i < probs.length; i++)
						probs[i] = Double.valueOf(tokens[i + 1]);
					hashesWithCondProbs.put(tokens[0], probs);
				}
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
		return hashesWithCondProbs;
	}

	public static HashMap<String, Double[]> extractDistinctiveHashesByCondProbs(
			String filePath, String extension, String signatureType) {
		// Top-ranked hash features file name generation
		String rankedHashesPath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)
				+ (extension + Constants.UNDERSCORE + "distinctive"
						+ Constants.UNDERSCORE + signatureType
						+ Constants.UNDERSCORE + "by_cond_probs.tsv")
						.toLowerCase();
		File rankedHashesFile = new File(rankedHashesPath);

		// This will keep the conditional probabilities of each hash for each
		// class: P(g|C_i)
		HashMap<String, Double[]> hashesWithCondProbs = readCondProbsOfHashesFromFile(filePath);
		int topRankedSize = Integer.parseInt(FileHandler
				.readConfigValue(Constants.TOP_RANKED_SIZE_CONFIG));
		// This structure will keep the top-ranked hashes with their information
		// gain

		ScorePair[] topRankedHashes = new ScorePair[topRankedSize];
		ScorePair[] topRankedHashesForClassA = new ScorePair[topRankedSize / 2];
		ScorePair[] topRankedHashesForClassB = new ScorePair[topRankedSize / 2];

		try {
			// Initialize top-ranked array values for ordering and comparison
			for (int i = 0; i < topRankedHashesForClassA.length; i++) {
				topRankedHashesForClassA[i] = new ScorePair(
						Integer.toString(i), 0.0);
				topRankedHashesForClassB[i] = new ScorePair(
						Integer.toString(i), 0.0);
			}

			for (Map.Entry<String, Double[]> entry : hashesWithCondProbs
					.entrySet()) {

				double dif = (entry.getValue()[0] - entry.getValue()[1])
						/ (entry.getValue()[0] + entry.getValue()[1]);
				// Find the first minimum value and its index in top-ranked
				// array to replace-> index0:index of the item, index 1-> value
				// of item
				if (dif > 0.0) {
					double[] minIGA = minIndexAndValue(topRankedHashesForClassA);

					if (entry.getValue()[0] > minIGA[1]) {
						topRankedHashesForClassA[(int) minIGA[0]] = new ScorePair(
								entry.getKey(), dif);
					}
				} else if (dif < 0.0) {
					double[] minIGB = minIndexAndValue(topRankedHashesForClassB);
					if (entry.getValue()[1] > minIGB[1]) {
						topRankedHashesForClassB[(int) minIGB[0]] = new ScorePair(
								entry.getKey(), Math.abs(dif));
					}
				}
			}
			// Sort top ranked array and print it to file and console
			topRankedHashes = ArrayUtils.addAll(topRankedHashesForClassA,
					topRankedHashesForClassB);
			Arrays.sort(topRankedHashes);

			FileUtils.write(rankedHashesFile, "Rank" + Constants.TAB_CHAR
					+ "Hash" + Constants.TAB_CHAR + "Class Difference" + "\n",
					true);
			System.out.print("Rank" + Constants.TAB_CHAR + "Hash"
					+ Constants.TAB_CHAR + "Class Difference" + "\n");
			for (int i = 0; i < topRankedHashes.length; i++) {
				System.out.print((i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + "\n");
				FileUtils.write(rankedHashesFile, (i + 1) + Constants.TAB_CHAR
						+ topRankedHashes[i].getKey() + Constants.TAB_CHAR
						+ topRankedHashes[i].getValue() + "\n", true);
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
		return hashesWithCondProbs;
	}

	public static ArrayList<HashSet<String>> readDistinctiveHashesFromFile(
			String filePath, ArrayList<Integer> inputSizes) throws IOException {
		ArrayList<HashSet<String>> rankedHashesSets = new ArrayList<HashSet<String>>();
		for (int j = 0; j < inputSizes.size(); j++) {
			HashSet<String> topRankedHashes = new HashSet<String>();
			List<String> fileLines = FileUtils.readLines(new File(filePath));
			for (int i = 1; i <= inputSizes.get(j); i++) {
				String[] values = fileLines.get(i).split(Constants.TAB_CHAR);
				topRankedHashes.add(values[1]);
			}
			rankedHashesSets.add(topRankedHashes);
		}
		return rankedHashesSets;
	}

	public static ArrayList<HashSet<String>> readDistinctiveHashesFromFiles(
			String filePattern, ArrayList<Integer> inputSizes)
			throws IOException {
		ArrayList<HashSet<String>> rankedHashesSets = new ArrayList<HashSet<String>>();
		File dir = new File(
				FileHandler.readConfigValue(Constants.REPORTS_PATH_CONFIG));
		File[] matchingFiles = dir.listFiles(new FilenameFilter() {
			public boolean accept(File dir, String name) {
				return name.startsWith(filePattern) && name.endsWith(".tsv");
			}
		});
		File fileIndexes = new File(
				FileHandler.readConfigValue(Constants.REPORTS_PATH_CONFIG)
						+ File.separator + "hashes_distinctive_files_list.txt");
		FileUtils.write(fileIndexes, "pattern:" + filePattern + "\n", true);
		for (int k = 0; k < matchingFiles.length; k++) {
			FileUtils.write(fileIndexes, k + ":" + matchingFiles[k].getName()
					+ "\n", true);
			for (int j = 0; j < inputSizes.size(); j++) {
				HashSet<String> topRankedHashes = new HashSet<String>();
				List<String> fileLines = FileUtils.readLines(matchingFiles[k]);
				for (int i = 1; i <= inputSizes.get(j); i++) {
					String[] values = fileLines.get(i)
							.split(Constants.TAB_CHAR);
					topRankedHashes.add(values[1]);
				}
				rankedHashesSets.add(topRankedHashes);
			}
		}
		return rankedHashesSets;
	}

	public static void generateDistinctiveHashesFiles(String dataPath,
			String extension, boolean isTestData) {
		String signatureType = FileHandler
				.readConfigValue(Constants.SIGNATURE_ENTITY_TYPE);
		HashMap<String, Short[]> hashes = constructHashes(dataPath, extension,
				isTestData, signatureType);
		extractDistinctiveHashesByNormalizedAngle(hashes, extension);
		extractDistinctiveHashesByIG(hashes, extension);
		extractDistinctiveHashesByClasswiseIG(hashes, extension);
		//printFrequenciesOfHashes(hashes, signatureType);
		// calculateCondProbsOfHashes(hashes, signatureType);

	}

	public static String prepareWekaFileHeader(HashSet<String> topRankedHashes,
			String extension, boolean isTestData, int numberOfDataInput,
			String signatureType, String extractionMethodology)
			throws IOException {
		// Data class label for reports and input files

		String trainOrTestLabel = isTestData ? Constants.TEST_LABEL
				: Constants.TRAIN_LABEL;

		// Generate data file and prepare it with its headers
		String wekaDataFilePath = FileHandler
				.readConfigValue(Constants.REPORTS_PATH_CONFIG)+
				trainOrTestLabel + File.separator
				+ (trainOrTestLabel + Constants.UNDERSCORE + extension
						+ Constants.UNDERSCORE + signatureType
						+ Constants.UNDERSCORE + numberOfDataInput
						+ Constants.UNDERSCORE + extractionMethodology + ".arff")
						.toLowerCase();

		File wekaDataFile = new File(wekaDataFilePath);
		FileUtils.deleteQuietly(wekaDataFile);

		FileUtils
				.write(wekaDataFile,
						"%%%\n"
								+ "% This "
								+ trainOrTestLabel.toLowerCase()
								+ " data file consists of the most distictive hashes extracted\n"
								+ "% from reversed engineered *."
								+ extension
								+ " files of known Android apps\n"
								+ "% to classify unknown Anroid apps as "
								+ Constants.CLASS_A_NAME.toLowerCase()
								+ " or "
								+ Constants.CLASS_B_NAME.toLowerCase()
								+ " application\n"
								+ "% by using Weka classifier algorithms. The study is being conducted\n"
								+ "% by Munir Geden and Jens Krinke as part of a research in UCL.\n"
								+ "%\n" + "@relation 'hash'\n", true);

		// FileUtils.write(wekaDataFile, "@attribute appname string\n", true);
		for (String entry : topRankedHashes) {
			String md5 = new String(DigestUtils.md5Hex(entry));
			FileUtils.write(wekaDataFile, "@attribute " + md5 + " numeric\n",
					true);
		}

		FileUtils.write(wekaDataFile,
				"@attribute class {" + Constants.CLASS_A_NAME + ","
						+ Constants.CLASS_B_NAME + "}\n", true);
		FileUtils.write(wekaDataFile, "@data\n", true);
		return wekaDataFilePath;
	}

	public static void prepareWekaFileDataPerApp(
			ArrayList<HashSet<String>> topRankedHashesListSet, String appPath,
			ArrayList<String> dataFilePaths, String extension,
			boolean isTestData, String signatureType) {

		try {

			// Arff file that will keep training data values
			ArrayList<File> dataFiles = new ArrayList<File>();
			for (String s : dataFilePaths)
				dataFiles.add(new File(s));

			// Collect all files under the path of given app
			Collection<File> files = FileHandler.findFiles(appPath,
					new String[] { extension });

			ArrayList<HashMap<String, Integer>> calculatedDatas = new ArrayList<HashMap<String, Integer>>();
			for (HashSet<String> rankedList : topRankedHashesListSet) {
				HashMap<String, Integer> calculatedData = new HashMap<String, Integer>();
				for (String entry : rankedList) {
					calculatedData.put(entry, 0);
				}
				calculatedDatas.add(calculatedData);
			}
			// Retrieve class type, its name and its integer array index from
			// file path
			boolean taxon = appPath.contains(File.separator
					+ Constants.CLASS_A_NAME + File.separator);
			String className = taxon ? Constants.CLASS_A_NAME
					: Constants.CLASS_B_NAME;

			// Find appName from path
			String appName = appNameOfFile(appPath, extension);

			// Print iteration information for console
			System.out.print("Analysing app... Class:" + className
					+ Constants.TAB_CHAR + "Extension:" + extension
					+ Constants.TAB_CHAR + "App Name:" + appName + "\n");

			// Number of files traversed
			int fileIterator = -1;

			// Performance monitor watch
			StopWatch watch = new StopWatch();
			watch.reset();
			watch.start();
			HashSet<String> hashes = new HashSet<String>();
			// Traverse app files to be analyzed
			for (File file : files) {
				fileIterator++;
				// Read files as byte array and convert them to hexadecimal
				// strings
				String[] fileContent = FileHandler.readFileToString(
						file.getAbsolutePath()).split("\n");
				String patternString = "";
				if (extension.equals(Constants.BERTILLONAGE_CLASS_EXTENSION)
						|| extension
								.equals(Constants.BERTILLONAGE_DEX_EXTENSION)) {
					if (signatureType.equals(Constants.CLASS_UNIT))
						patternString = "C:    ";
					else if (signatureType.equals(Constants.FIELD_UNIT))
						patternString = "\tF:    ";
					else if (signatureType.equals(Constants.METHOD_UNIT))
						patternString = "\tM:    ";
					else if (signatureType.equals(Constants.HASH_UNIT))
						patternString = "H:    ";
					else
						patternString = "H:    ";

					for (String s : fileContent) {
						if (s.startsWith(patternString)) {
							// String md5 = new
							// String(DigestUtils.md5Hex(s.substring(s.indexOf(patternString)
							// + patternString.length())));
							hashes.add(s.substring(s.indexOf(patternString)
									+ patternString.length()));
						}
					}
				} else if (extension.equals(Constants.PERM_EXTENSION)) {
					DocumentBuilderFactory dbFactory = DocumentBuilderFactory
							.newInstance();
					DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();
					Document doc = dBuilder.parse(file);
					doc.getDocumentElement().normalize();
					NodeList nList = doc
							.getElementsByTagName("uses-permission");
					for (int temp = 0; temp < nList.getLength(); temp++) {
						Node nNode = nList.item(temp);
						if (nNode.getNodeType() == Node.ELEMENT_NODE) {
							Element eElement = (Element) nNode;
							hashes.add(eElement.getAttribute("android:name"));
						}
					}
				} else if (extension.equals(Constants.MANF_EXTENSION)) {
					patternString = "SHA1-Digest: ";
					for (String s : fileContent) {
						if (s.startsWith(patternString)) {
							hashes.add(s.substring(s.indexOf(patternString)
									+ patternString.length()).replace("\n", "").replace("\r",""));
						}
					}
				}	
				for (String hash : hashes) {
					for (int k = 0; k < topRankedHashesListSet.size(); k++) {
						if (topRankedHashesListSet.get(k).contains(hash)) {
							if (calculatedDatas.get(k).containsKey(hash)) {
								calculatedDatas.get(k).put(hash, 1);
							}
						}
					}
				}

			}

			watch.stop();
			// Print the time elapsed to analyze the app.
			System.out.print("Completed... Elapsed Time:"
					+ (double) watch.getTime() / 1000.0 + " secs."
					+ Constants.TAB_CHAR + "Number of Files:"
					+ (fileIterator + 1) + "\n");

			for (int k = 0; k < topRankedHashesListSet.size(); k++) {

				// Append app inputs to arff file
				// FileUtils.write(dataFiles.get(k), appName + ",", true);
				for (Map.Entry<String, Integer> entry : calculatedDatas.get(k)
						.entrySet()) {
					FileUtils.write(dataFiles.get(k), entry.getValue() + ",",
							true);
				}
				FileUtils.write(dataFiles.get(k), className + "\n", true);
			}

		} catch (Exception e) {
			e.printStackTrace();
		}

	}

	public static void prepareWekaFiles(String topRankedFeaturesFile,
			String dataPath, String extension, boolean isTestData,
			ArrayList<Integer> inputSizes) {
		try {
			String signatureType = FileHandler
					.readConfigValue(Constants.SIGNATURE_ENTITY_TYPE);

			ArrayList<HashSet<String>> rankedHashesSets = readDistinctiveHashesFromFiles(
					topRankedFeaturesFile, inputSizes);
			ArrayList<String> dataFilePaths = new ArrayList<String>();
			for (int i = 0; i < rankedHashesSets.size(); i++) {
				HashSet<String> topRankedHashes = rankedHashesSets.get(i);
				String dataFilePath = prepareWekaFileHeader(topRankedHashes,
						extension, isTestData,
						inputSizes.get(i % inputSizes.size()), signatureType,
						Integer.toString(i / inputSizes.size()));
				dataFilePaths.add(dataFilePath);
			}
			String[] appPaths = appPathsOfGivenClass(dataPath, extension,
					isTestData);
			for (String appPath : appPaths) {
				prepareWekaFileDataPerApp(rankedHashesSets, appPath,
						dataFilePaths, extension, isTestData, signatureType);
			}

		} catch (Exception e) {
			e.printStackTrace();
		}

	}

	private static String[] appPathsOfGivenClass(String dataPath,
			String extension, boolean isTestData) {
		String dataTypeFolder = "";
		if (!(dataPath.contains(File.separator + Constants.TEST_LABEL
				+ File.separator) || dataPath.contains(File.separator
				+ Constants.TRAIN_LABEL + File.separator))) {
			dataTypeFolder = isTestData ? Constants.TEST_LABEL
					: Constants.TRAIN_LABEL;
		}
		String classPathA = dataPath + File.separator + dataTypeFolder
				+ File.separator + Constants.CLASS_A_NAME + File.separator
				+ extension.toUpperCase() + File.separator;
		String classPathB = dataPath + File.separator + dataTypeFolder
				+ File.separator + Constants.CLASS_B_NAME + File.separator
				+ extension.toUpperCase() + File.separator;
		String[] appPaths = ArrayUtils.addAll(
				FileHandler.findFolderContents(classPathA),
				FileHandler.findFolderContents(classPathB));
		return appPaths;
	}

	private static String appNameOfFile(String appPath, String extension) {
		// Retrieve app name from file path
		if (appPath.contains(Constants.UNDERSCORE + extension.toUpperCase())) {
			String[] folders = appPath.substring(
					0,
					appPath.lastIndexOf(Constants.UNDERSCORE
							+ extension.toUpperCase())).split(File.separator);
			return folders[folders.length - 1];
		} else {
			String[] folders = appPath.split(File.separator);
			return folders[folders.length - 1];
		}

	}

	private static double[] minIndexAndValue(ScorePair[] arr) {
		double minValue = Double.MAX_VALUE;
		int minIndex = 0;
		for (int i = 0; i < arr.length; i++) {
			if (arr[i].getValue() < minValue) {
				minValue = arr[i].getValue();
				minIndex = i;
			}
		}
		return new double[] { (double) minIndex, minValue };
	}

	public static int randWithinRange(int min, int max) {
		Random rand = new Random();
		int numValue = rand.nextInt((max - min) + 1) + min;
		return numValue;
	}

}